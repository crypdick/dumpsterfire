Shane and Noah made a script that counted the # unique editors and number of edits for every article in Wikipedia.

Richard used this to look for dumpsters. Dumpsters are articles that are obscure. To find dumpsters, I looked at the PDFs and CDFs for # editors and # edits and chose articles that had <100 unique editors and <200 editors. I also wanted to avoid articles that were _too_ obscure. So, I also discarded articles that had <=20 editors and <= unique editors. The resulting "whitelist" of article_ids for dumpsters is saved in 'results/dumpsters_list.txt'. The code for for the PDFs, CDFs, and filtering is in make_histograms.py.

Next, I wanted to scan the edit history of the dumpsters for days where there was a potential flame-way, AKA "fires". To find candidate days, I used the 'dumpsters_list' to exclusively select revisions on dumpster articles. Next, I grouped the edits by unique dates and counted how many edits were made by each unique editor. Since we are interested in finding flame wars, I then selected only days that had >=2 editors who made  >=4 unique edits apiece on the same article on the same day. The output of this job are (article_id, date) pairs. The objective is to then use these to grab a day worth of revision comments from dumpster articles that had many edits. The code for this is on test.py.
